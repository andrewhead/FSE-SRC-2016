% We are in the process of collecting developers' pathways through web documents when they answer social questions about packages.
Our data provides us with a rich picture of where developers find social signals.
We show a portrait in Figure~\ref{fig:visits} for just one developer answering three of the six questions.
Many domains that have been recently described as important to programmers---for instance, GitHub, Google, and Stack Overflow~\cite{storey_revolution_2014}---all have their place here, for various concerns.
Developers offload questions about the recency of documentation to GitHub issues, commit histories, and pull request contents;
they ask Stack Overflow, Reddit, and Google Groups about how welcoming communities are;
and GitHub profiles help determine developer histories.

We want to highlight a few guidelines that we anticipate for the design of social signals, based on the strategies we have seen developers undertake when answering these questions about packages.
First, references to text are necessary when developers are determining how welcoming communities are, and to understand whether their background matches that of the intended user.
Second, developers delegate questions to Google, Reddit, Quora, and blog posts.
On these channels, the presence or absence of information can be an answer in itself.
Third, given the organization of the web, deverloper inevitably need to sample questions, documents, and issues to develop approximate answers to complex questions about packages.

Furthermore, these preliminary findings motivate the need for better client-facing socially-enabled software telemetry displays.
It is common for a participant in our study to make a realization after twenty or thirty minutes of searching that changes their perception of a package, often only after the right question is asked---for example, discovering that a package's primary maintainer has been inactive for two years.
Furthermore, whearas quickly skimming pages for a package may provide a surface-level understanding of it's quality, w ehave seen that serious, sustained attention to the right code and documentation can help developers overcome early biases and premature negative judgments.
We believe that the obstacles developers face uncovering the true nature and strengths of packages is a product of developers' processes and the limitations of current information interfaces.
It's only with attention to both of these that we will be able to design the first generation of telemetry systems for helping developers answer deep, complex, social questions about software projects.

\if 0
Include the major insights that developers had during the study.
For example:
there's a new major version;
there's an examples repository that wasn't clearly shown;
there's a Google Groups page for the project;
the docs are actually pretty usable.
From this (and hopefully other insights) we see that a surface appearance of a package takes a while to build up accurately, and might require looking at a package from multiple different angles.
We think that it need not take so much time.

Not all developers seemed to agree on what information sources were best.
Part of this is likely because of prior knowledge.
One of the participants chose to look at the IRC channels for the package.

I want to touch upon each of the following.

What questions are participants least confident answering?

What are the most authoratative sources for answering each question?

What do they approximate to aggregate?

How much do participants' perceptions of documentation change?  And how much do their opinions change?

And what does this all suggest for what's broken for information presentation, and the design of programmers' front-end to the web?
\fi
