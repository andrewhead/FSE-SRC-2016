We observed several noteworthy strategies participants took to learn about a package's social health.
First, participants read relevant text to assess social health.
In particular, participants skimmed text from conversations to determine how welcoming communities were.
Participants also read texts from documentation about a project's API and development philosophy to determine if a package was designed for users with their backgrounds and goals.
Existing package comparison tools do not support reading relevant conversations and documentation.
Instead, such tools only show summary statistics (e.g.~\cite{awesome_python,ruby_toolbox}).

Participants sometimes looked for social health cues in the form of advice from current users of a package.
Participants queried the web through search engines to find pre-built summaries describing the community and documentation.
Participants found explicit comparisons of packages on Reddit, and user testimonials on Quora.
One participant consulted issue reports to determine how up-to-date documentation was.
When participants looked at texts of questions, documents, and issue reports, they chose a handful of pages from dozens or even hundreds.

Our URL log data suggests common places where participants found social health cues.
Participants relied on different types of web pages when answering each social health question.
We have seen participants find:
(1) whether a community is welcoming by viewing Q\&A sites and discussions on Reddit and Google Groups;
(2) documentation recency by viewing issue reports, code contribution histories, and pull request contents;
(3) the trustworthiness of developers by viewing issue reports, and profiles on code hosting sites.
Figure~\ref{fig:visits} shows a cross-section of the URLs one participant visited when answering three of the six questions.
We leave quantitative analysis of these trends and a full exploration of specific cues from these sites for future work.

Our preliminary results confirm a need for search tools that reveal obscure information about social health quickly.
Participants frequently realized they missed important information after twenty or thirty minutes of learning about a package.
One participant wrongly assessed a package had no community at all.
Another participant failed to find a newer version of a package under a different name.
And another participant missed large repositories of example code written by the package's developers.
Such incorrect judgments could be costly to reverse:
One participant read source code before realizing that one package's programming API was preferable to one he favored before.

We believe these incorrect judgments are a product of developers' habits and the limitations of current information interfaces.
With attention to both, we can design more powerful search tools to help developers quickly and effectively learn about packages' social health when choosing between them.
For now, these preliminary results suggest that
package consumers should not trust their initial instincts,
and should inspect comparisons, discussions, and Q\&A for a well-informed picture of a package's social health.
Developers should know that cues about the social health for their projects could exist on dozens of domains,
and potential consumers may need help learning where to look for help.
